{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gae_amazon_photo",
      "provenance": [],
      "machine_shape": "hm",
      "background_execution": "on"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "3adUfVtrRMVX"
      },
      "outputs": [],
      "source": [
        "# Install required packages.\n",
        "!pip install -q torch-scatter -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q torch-sparse -f https://data.pyg.org/whl/torch-1.10.0+cu113.html\n",
        "!pip install -q git+https://github.com/pyg-team/pytorch_geometric.git\n",
        "\n",
        "# Helper function for visualization.\n",
        "%matplotlib inline\n",
        "import torch\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def visualize_graph(G, color):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=False,\n",
        "                     node_color=color, cmap=\"Set2\")\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "def visualize_embedding(h, color, epoch=None, loss=None):\n",
        "    plt.figure(figsize=(7,7))\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    h = h.detach().cpu().numpy()\n",
        "    plt.scatter(h[:, 0], h[:, 1], s=140, c=color, cmap=\"Set2\")\n",
        "    if epoch is not None and loss is not None:\n",
        "        plt.xlabel(f'Epoch: {epoch}, Loss: {loss.item():.4f}', fontsize=16)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch_geometric.datasets import Amazon\n",
        "from torch_geometric.utils import *\n",
        "\n",
        "dataset = Amazon(root='/tmp/Amazon', name='Computers')\n",
        "print(dataset[0])\n",
        "print(dataset[0].x)\n",
        "print(dataset[0].edge_index)\n",
        "adj =  to_scipy_sparse_matrix(dataset[0].edge_index, edge_attr=dataset[0].edge_attr)\n",
        "print(adj)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qXfN9slARblk",
        "outputId": "b586698e-ff00-438f-80a9-14d3ce94e80c"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data(x=[13752, 767], edge_index=[2, 491722], y=[13752])\n",
            "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 0.,  ..., 0., 1., 0.],\n",
            "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
            "        [1., 1., 0.,  ..., 1., 1., 0.]])\n",
            "tensor([[    0,     0,     0,  ..., 13751, 13751, 13751],\n",
            "        [  507,  6551,  8210,  ..., 12751, 13019, 13121]])\n",
            "  (0, 507)\t1.0\n",
            "  (0, 6551)\t1.0\n",
            "  (0, 8210)\t1.0\n",
            "  (0, 9745)\t1.0\n",
            "  (1, 184)\t1.0\n",
            "  (1, 206)\t1.0\n",
            "  (1, 337)\t1.0\n",
            "  (1, 638)\t1.0\n",
            "  (1, 872)\t1.0\n",
            "  (1, 1272)\t1.0\n",
            "  (1, 1456)\t1.0\n",
            "  (1, 1517)\t1.0\n",
            "  (1, 1559)\t1.0\n",
            "  (1, 2073)\t1.0\n",
            "  (1, 2159)\t1.0\n",
            "  (1, 2316)\t1.0\n",
            "  (1, 2396)\t1.0\n",
            "  (1, 2414)\t1.0\n",
            "  (1, 2764)\t1.0\n",
            "  (1, 2772)\t1.0\n",
            "  (1, 2791)\t1.0\n",
            "  (1, 2965)\t1.0\n",
            "  (1, 3080)\t1.0\n",
            "  (1, 3354)\t1.0\n",
            "  (1, 3957)\t1.0\n",
            "  :\t:\n",
            "  (13751, 1280)\t1.0\n",
            "  (13751, 1796)\t1.0\n",
            "  (13751, 2155)\t1.0\n",
            "  (13751, 2485)\t1.0\n",
            "  (13751, 2673)\t1.0\n",
            "  (13751, 4239)\t1.0\n",
            "  (13751, 5278)\t1.0\n",
            "  (13751, 6298)\t1.0\n",
            "  (13751, 6530)\t1.0\n",
            "  (13751, 6625)\t1.0\n",
            "  (13751, 6963)\t1.0\n",
            "  (13751, 8286)\t1.0\n",
            "  (13751, 8927)\t1.0\n",
            "  (13751, 9162)\t1.0\n",
            "  (13751, 9241)\t1.0\n",
            "  (13751, 9705)\t1.0\n",
            "  (13751, 11273)\t1.0\n",
            "  (13751, 11331)\t1.0\n",
            "  (13751, 12012)\t1.0\n",
            "  (13751, 12013)\t1.0\n",
            "  (13751, 12081)\t1.0\n",
            "  (13751, 12479)\t1.0\n",
            "  (13751, 12751)\t1.0\n",
            "  (13751, 13019)\t1.0\n",
            "  (13751, 13121)\t1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.optim import Adam\n",
        "from sklearn.metrics import roc_auc_score, average_precision_score\n",
        "import scipy.sparse as sp\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "3dWc1FvCcURm"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Args:\n",
        "  dataset = 'amazon_computers'\n",
        "  model = 'GAE'\n",
        "\n",
        "  input_dim = 767 \n",
        "  hidden1_dim = 32\n",
        "  hidden2_dim = 16\n",
        "  use_feature = True\n",
        "\n",
        "  num_epoch = 200\n",
        "  learning_rate = 0.01\n",
        "args=Args()"
      ],
      "metadata": {
        "id": "dHgHc3tZd3a9"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "****************NOTE*****************\n",
        "CREDITS : Thomas Kipf\n",
        "since datasets are the same as those in kipf's implementation, \n",
        "Their preprocessing source was used as-is.\n",
        "*************************************\n",
        "'''\n",
        "import numpy as np\n",
        "import sys\n",
        "import pickle as pkl\n",
        "import networkx as nx\n",
        "import scipy.sparse as sp\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "colab='Colab Notebooks'\n",
        "path = F\"/content/gdrive/My Drive/{colab}/GraphNN/data/\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CKX8KX0tie_m",
        "outputId": "584617b6-c829-4495-a4d4-374df8b5a9f7"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import scipy.sparse as sp\n",
        "\n",
        "def sparse_to_tuple(sparse_mx):\n",
        "    if not sp.isspmatrix_coo(sparse_mx):\n",
        "        sparse_mx = sparse_mx.tocoo()\n",
        "    coords = np.vstack((sparse_mx.row, sparse_mx.col)).transpose()\n",
        "    values = sparse_mx.data\n",
        "    shape = sparse_mx.shape\n",
        "    return coords, values, shape\n",
        "\n",
        "def preprocess_graph(adj):\n",
        "    adj = sp.coo_matrix(adj)\n",
        "    adj_ = adj + sp.eye(adj.shape[0])\n",
        "    rowsum = np.array(adj_.sum(1))\n",
        "    degree_mat_inv_sqrt = sp.diags(np.power(rowsum, -0.5).flatten())\n",
        "    adj_normalized = adj_.dot(degree_mat_inv_sqrt).transpose().dot(degree_mat_inv_sqrt).tocoo()\n",
        "    return sparse_to_tuple(adj_normalized)\n",
        "\n",
        "def mask_test_edges(adj):\n",
        "    # Function to build test set with 10% positive links\n",
        "    # NOTE: Splits are randomized and results might slightly deviate from reported numbers in the paper.\n",
        "    # TODO: Clean up.\n",
        "\n",
        "    # Remove diagonal elements\n",
        "    adj = adj - sp.dia_matrix((adj.diagonal()[np.newaxis, :], [0]), shape=adj.shape)\n",
        "    adj.eliminate_zeros()\n",
        "    # Check that diag is zero:\n",
        "    assert np.diag(adj.todense()).sum() == 0\n",
        "\n",
        "    adj_triu = sp.triu(adj)\n",
        "    adj_tuple = sparse_to_tuple(adj_triu)\n",
        "    edges = adj_tuple[0]\n",
        "    edges_all = sparse_to_tuple(adj)[0]\n",
        "    #num_test = int(np.floor(edges.shape[0] / 60.))\n",
        "    #num_val = int(np.floor(edges.shape[0] / 10.))\n",
        "    num_val=int(edges.shape[0]*0.1)\n",
        "    num_test=int(edges.shape[0]*0.6)\n",
        "    all_edge_idx = list(range(edges.shape[0]))\n",
        "    np.random.shuffle(all_edge_idx)\n",
        "    val_edge_idx = all_edge_idx[:num_val]\n",
        "    test_edge_idx = all_edge_idx[num_val:(num_val + num_test)]\n",
        "    test_edges = edges[test_edge_idx]\n",
        "    val_edges = edges[val_edge_idx]\n",
        "    train_edges = np.delete(edges, np.hstack([test_edge_idx, val_edge_idx]), axis=0)\n",
        "\n",
        "    def ismember(a, b, tol=5):\n",
        "        rows_close = np.all(np.round(a - b[:, None], tol) == 0, axis=-1)\n",
        "        return np.any(rows_close)\n",
        "\n",
        "    test_edges_false = []\n",
        "    while len(test_edges_false) < len(test_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        # if idx_i == idx_j:\n",
        "        #     continue\n",
        "        # if ismember([idx_i, idx_j], edges_all):\n",
        "        #     continue\n",
        "        # if test_edges_false:\n",
        "        #     if ismember([idx_j, idx_i], np.array(test_edges_false)):\n",
        "        #         continue\n",
        "        #     if ismember([idx_i, idx_j], np.array(test_edges_false)):\n",
        "        #         continue\n",
        "        test_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    val_edges_false = []\n",
        "    while len(val_edges_false) < len(val_edges):\n",
        "        idx_i = np.random.randint(0, adj.shape[0])\n",
        "        idx_j = np.random.randint(0, adj.shape[0])\n",
        "        # if idx_i == idx_j:\n",
        "        #     continue\n",
        "        # if ismember([idx_i, idx_j], train_edges):\n",
        "        #     continue\n",
        "        # if ismember([idx_j, idx_i], train_edges):\n",
        "        #     continue\n",
        "        # if ismember([idx_i, idx_j], val_edges):\n",
        "        #     continue\n",
        "        # if ismember([idx_j, idx_i], val_edges):\n",
        "        #     continue\n",
        "        # if val_edges_false:\n",
        "        #     if ismember([idx_j, idx_i], np.array(val_edges_false)):\n",
        "        #         continue\n",
        "        #     if ismember([idx_i, idx_j], np.array(val_edges_false)):\n",
        "        #         continue\n",
        "        val_edges_false.append([idx_i, idx_j])\n",
        "\n",
        "    # assert ~ismember(test_edges_false, edges_all)\n",
        "    # assert ~ismember(val_edges_false, edges_all)\n",
        "    # assert ~ismember(val_edges, train_edges)\n",
        "    # assert ~ismember(test_edges, train_edges)\n",
        "    # assert ~ismember(val_edges, test_edges)\n",
        "\n",
        "    data = np.ones(train_edges.shape[0])\n",
        "\n",
        "    # Re-build adj matrix\n",
        "    adj_train = sp.csr_matrix((data, (train_edges[:, 0], train_edges[:, 1])), shape=adj.shape)\n",
        "    adj_train = adj_train + adj_train.T\n",
        "\n",
        "    # NOTE: these edge lists only contain single direction of edge!\n",
        "    return adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false"
      ],
      "metadata": {
        "id": "eseTK7AAjQNA"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "class GraphConvSparse(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim, adj, activation = F.relu, **kwargs):\n",
        "        super(GraphConvSparse, self).__init__(**kwargs)\n",
        "        self.weight = glorot_init(input_dim, output_dim) \n",
        "        self.adj = adj\n",
        "        self.activation = activation\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        x = inputs\n",
        "        x = torch.mm(x,self.weight)\n",
        "        x = torch.mm(self.adj, x)\n",
        "        outputs = self.activation(x)\n",
        "        return outputs\n",
        "\n",
        "\n",
        "def dot_product_decode(Z):\n",
        "    A_pred = torch.sigmoid(torch.matmul(Z,Z.t()))\n",
        "    return A_pred\n",
        "\n",
        "def glorot_init(input_dim, output_dim):\n",
        "    init_range = np.sqrt(6.0/(input_dim + output_dim))\n",
        "    initial = torch.rand(input_dim, output_dim)*2*init_range - init_range\n",
        "    return nn.Parameter(initial)\n",
        "\n",
        "\n",
        "class GAE(nn.Module):\n",
        "    def __init__(self,adj):\n",
        "        super(GAE,self).__init__()\n",
        "        self.base_gcn = GraphConvSparse(args.input_dim, args.hidden1_dim, adj)\n",
        "        self.gcn_mean = GraphConvSparse(args.hidden1_dim, args.hidden2_dim, adj, activation=lambda x:x)\n",
        "\n",
        "    def encode(self, X):\n",
        "        hidden = self.base_gcn(X)\n",
        "        z = self.mean = self.gcn_mean(hidden)\n",
        "        return z\n",
        "\n",
        "    def forward(self, X):\n",
        "        Z = self.encode(X)\n",
        "        A_pred = dot_product_decode(Z)\n",
        "        return A_pred"
      ],
      "metadata": {
        "id": "WKs4MiOZjYje"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_features(features):\n",
        "    \"\"\"Row-normalize feature matrix and convert to tuple representation\"\"\"\n",
        "    rowsum = np.array(features.sum(1))\n",
        "    r_inv = np.power(abs(rowsum), -1).flatten()\n",
        "    r_inv[np.isinf(r_inv)] = 0.\n",
        "    r_mat_inv = sp.diags(r_inv)\n",
        "    features = r_mat_inv.dot(features)\n",
        "    if isinstance(features, np.ndarray):\n",
        "        features = sp.csr_matrix(features)\n",
        "    return sparse_to_tuple(features)"
      ],
      "metadata": {
        "id": "87BwcjIlUxwp"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['CUDA_VISIBLE_DEVICES'] = \"\"\n",
        "from scipy import sparse\n",
        "#adj, features = load_data(args.dataset)\n",
        "adj = sparse.csr_matrix(adj)\n",
        "features = dataset[0].x\n",
        "# Store original adjacency matrix (without diagonal entries) for later\n",
        "adj_orig = adj\n",
        "adj_orig = adj_orig - sp.dia_matrix((adj_orig.diagonal()[np.newaxis, :], [0]), shape=adj_orig.shape)\n",
        "adj_orig.eliminate_zeros()\n",
        "\n",
        "adj_train, train_edges, val_edges, val_edges_false, test_edges, test_edges_false = mask_test_edges(adj)\n",
        "adj = adj_train\n",
        "# Some preprocessing\n",
        "adj_norm = preprocess_graph(adj)\n",
        "\n",
        "num_nodes = adj.shape[0]\n",
        "\n",
        "features = preprocess_features(features.numpy().astype(float))\n",
        "num_features = features[2][1]\n",
        "features_nonzero = features[1].shape[0]\n",
        "\n",
        "# Create Model\n",
        "pos_weight = float(adj.shape[0] * adj.shape[0] - adj.sum()) / adj.sum()\n",
        "norm = adj.shape[0] * adj.shape[0] / float((adj.shape[0] * adj.shape[0] - adj.sum()) * 2)\n",
        "\n",
        "\n",
        "adj_label = adj_train + sp.eye(adj_train.shape[0])\n",
        "adj_label = sparse_to_tuple(adj_label)\n",
        "\n",
        "\n",
        "adj_norm = torch.sparse.FloatTensor(torch.LongTensor(adj_norm[0].T), torch.FloatTensor(adj_norm[1]), torch.Size(adj_norm[2]))\n",
        "adj_label = torch.sparse.FloatTensor(torch.LongTensor(adj_label[0].T),  torch.FloatTensor(adj_label[1]), torch.Size(adj_label[2]))\n",
        "features = torch.sparse.FloatTensor(torch.LongTensor(features[0].T), torch.FloatTensor(features[1]), torch.Size(features[2]))\n",
        "\n",
        "\n",
        "weight_mask = adj_label.to_dense().view(-1) == 1\n",
        "weight_tensor = torch.ones(weight_mask.size(0)) \n",
        "weight_tensor[weight_mask] = pos_weight\n",
        "\n",
        "# init model and optimizer\n",
        "#model = getattr(model,\"GAE\")(adj_norm)\n",
        "#model=VGAE(adj_norm)\n",
        "\n",
        "model=GAE(adj_norm)\n",
        "optimizer = Adam(model.parameters(), lr=args.learning_rate)\n",
        "\n",
        "\n",
        "def get_scores(edges_pos, edges_neg, adj_rec):\n",
        "\n",
        "    def sigmoid(x):\n",
        "        return 1 / (1 + np.exp(-x))\n",
        "\n",
        "    # Predict on test set of edges\n",
        "    preds = []\n",
        "    pos = []\n",
        "    for e in edges_pos:\n",
        "        # print(e)\n",
        "        # print(adj_rec[e[0], e[1]])\n",
        "        preds.append(sigmoid(adj_rec[e[0], e[1]].item()))\n",
        "        pos.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_neg = []\n",
        "    neg = []\n",
        "    for e in edges_neg:\n",
        "\n",
        "        preds_neg.append(sigmoid(adj_rec[e[0], e[1]].data))\n",
        "        neg.append(adj_orig[e[0], e[1]])\n",
        "\n",
        "    preds_all = np.hstack([preds, preds_neg])\n",
        "    labels_all = np.hstack([np.ones(len(preds)), np.zeros(len(preds_neg))])\n",
        "    roc_score = roc_auc_score(labels_all, preds_all)\n",
        "    ap_score = average_precision_score(labels_all, preds_all)\n",
        "\n",
        "    return roc_score, ap_score\n",
        "\n",
        "def get_acc(adj_rec, adj_label):\n",
        "    labels_all = adj_label.to_dense().view(-1).long()\n",
        "    preds_all = (adj_rec > 0.5).view(-1).long()\n",
        "    accuracy = (preds_all == labels_all).sum().float() / labels_all.size(0)\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "3IK_Tf6zjcfP"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train model\n",
        "for epoch in range(1500):\n",
        "    t = time.time()\n",
        "\n",
        "    A_pred = model(features)\n",
        "    optimizer.zero_grad()\n",
        "    loss = log_lik = norm*F.binary_cross_entropy(A_pred.view(-1), adj_label.to_dense().view(-1), weight = weight_tensor)\n",
        "    if args.model == 'VGAE':\n",
        "        kl_divergence = 0.5/ A_pred.size(0) * (1 + 2*model.logstd - model.mean**2 - torch.exp(model.logstd)).sum(1).mean()\n",
        "        loss -= kl_divergence\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    train_acc = get_acc(A_pred,adj_label)\n",
        "\n",
        "    val_roc, val_ap = get_scores(val_edges, val_edges_false, A_pred)\n",
        "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(loss.item()),\n",
        "          \"train_acc=\", \"{:.5f}\".format(train_acc), \"val_roc=\", \"{:.5f}\".format(val_roc),\n",
        "          \"val_ap=\", \"{:.5f}\".format(val_ap),\n",
        "          \"time=\", \"{:.5f}\".format(time.time() - t))\n",
        "\n",
        "\n",
        "\n",
        "test_roc, test_ap = get_scores(test_edges, test_edges_false, A_pred)\n",
        "print(\"End of training!\", \"test_roc=\", \"{:.5f}\".format(test_roc),\n",
        "      \"test_ap=\", \"{:.5f}\".format(test_ap))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lJJUeP-2VpOs",
        "outputId": "099ee303-43f2-450e-dda6-2496155308b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0001 train_loss= 0.72542 train_acc= 0.03343 val_roc= 0.81393 val_ap= 0.80411 time= 6.66648\n",
            "Epoch: 0002 train_loss= 0.72510 train_acc= 0.00085 val_roc= 0.79860 val_ap= 0.81011 time= 5.74884\n",
            "Epoch: 0003 train_loss= 0.72418 train_acc= 0.00085 val_roc= 0.79723 val_ap= 0.80951 time= 4.98660\n",
            "Epoch: 0004 train_loss= 0.72234 train_acc= 0.00085 val_roc= 0.79703 val_ap= 0.80963 time= 4.67159\n",
            "Epoch: 0005 train_loss= 0.71924 train_acc= 0.00085 val_roc= 0.79667 val_ap= 0.80935 time= 4.64679\n",
            "Epoch: 0006 train_loss= 0.71449 train_acc= 0.00085 val_roc= 0.79577 val_ap= 0.80850 time= 4.56576\n",
            "Epoch: 0007 train_loss= 0.70797 train_acc= 0.00085 val_roc= 0.79548 val_ap= 0.80825 time= 4.52849\n",
            "Epoch: 0008 train_loss= 0.69983 train_acc= 0.00085 val_roc= 0.79562 val_ap= 0.80840 time= 4.56503\n",
            "Epoch: 0009 train_loss= 0.69073 train_acc= 0.00085 val_roc= 0.79522 val_ap= 0.80801 time= 4.59995\n",
            "Epoch: 0010 train_loss= 0.68262 train_acc= 0.00085 val_roc= 0.79506 val_ap= 0.80787 time= 4.59025\n"
          ]
        }
      ]
    }
  ]
}